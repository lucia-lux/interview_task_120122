{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input directory path\n",
    "input_dir = os.getcwd()\n",
    "infilename = \"data.csv\"\n",
    "# read input data file\n",
    "in_df = pd.read_csv(os.path.join(input_dir, infilename))\n",
    "# drop columns that contain only nans\n",
    "#in_df = in_df.dropna(how = 'all', axis = 1)\n",
    "#in_df = in_df.rename(columns = {'Gender (1 = male, 2 = female)':'Gender'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess_Dataframe:\n",
    "\n",
    "    \"\"\" Preprocess input dataframe\"\"\"\n",
    "\n",
    "    def __init__(self, in_df):\n",
    "        self.in_df = in_df\n",
    "    \n",
    "    def remove_all_nans(self, axis_type: str):\n",
    "        \"\"\"\n",
    "        Remove rows or columns containing all NaNs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        axis_type:  str\n",
    "            'rows' or 'columns'\n",
    "        \"\"\"\n",
    "        if axis_type == 'rows':\n",
    "            self.in_df = self.in_df.dropna(how = 'all')\n",
    "        else:\n",
    "            self.in_df = self.in_df.dropna(how = 'all', axis = 1)\n",
    "    \n",
    "    def add_ids(self, id_vals = None):\n",
    "        \"\"\"\n",
    "        Add id column.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_df:  pd DataFrame\n",
    "            Dataframe to operate on\n",
    "        \n",
    "        \"\"\"\n",
    "        if not id_vals:\n",
    "            self.in_df['id'] = np.arange(1,self.in_df.shape[0]+1)\n",
    "        else:\n",
    "            self.in_df['id'] = id_vals \n",
    "    \n",
    "    def rename_cols(self, old_names: list, new_names: list ):\n",
    "        \"\"\"\n",
    "        Renames specified columns to specified new names.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        old_names:  list of str\n",
    "            names of columns to be renamed\n",
    "        new_names:  list of str\n",
    "            new column names\n",
    "        \"\"\"\n",
    "        zipped_lists = zip(old_names, new_names)\n",
    "        names_dict = dict(zipped_lists)\n",
    "        self.in_df = self.in_df.rename(columns = names_dict)\n",
    "\n",
    "    def prep_col_names(self, filter_by, suffix, split_by_num = None, suffix_2 = None):\n",
    "        \"\"\"\n",
    "        Prep column names for use of wid_to_long method\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filter_by: str\n",
    "            substring to filter columns by\n",
    "        prefix: str\n",
    "            specify desired prefix\n",
    "            for wide_to_long conversion\n",
    "        \"\"\"\n",
    "        cols_to_prep = self.in_df.filter(like = filter_by, axis = 1).columns\n",
    "        if not split_by_num:\n",
    "            # NB: reduces flexibility, but can always use method overriding & child class if no longer\n",
    "            # appropriate.\n",
    "            prepped_col_names = ['_'.join([name.split()[0],suffix]) for name in cols_to_prep]\n",
    "            self.rename_cols(cols_to_prep,prepped_col_names)\n",
    "        else:\n",
    "            new_names = ['numdays','enjoy','difficult']\n",
    "            #prepped_col_names = ['_'.join([name, suffix]) for name in cols_to_prep[:split_by_num]]\n",
    "            prepped_col_names = ['_'.join([name, suffix]) for name in new_names]\n",
    "            prepped_col_names.extend(['_'.join([name, suffix_2]) for name in new_names])\n",
    "            self.rename_cols(cols_to_prep,prepped_col_names)\n",
    "\n",
    "\n",
    "    def reshape_data(self):\n",
    "        \"\"\"\n",
    "        reshape df from wide to long format\n",
    "\n",
    "        \"\"\"\n",
    "        col_names =  list(set([name.split('_')[0] for name in self.in_df.columns[3:-1]]))\n",
    "        self.in_df_long = pd.wide_to_long(self.in_df, col_names,i = \"id\", j = \"time\", sep = '_').reset_index()\n",
    "    \n",
    "    def prepare_df(self):\n",
    "        \"\"\"\n",
    "        Preprocess dataframe.\n",
    "        \"\"\"\n",
    "        for index_name in ['rows','columns']:\n",
    "            self.remove_all_nans(index_name)\n",
    "        self.add_ids()\n",
    "        gender_col = self.in_df.filter(like = 'Gender',axis = 1).columns\n",
    "        self.rename_cols([gender_col[0], 'GHQ'], [gender_col[0].split()[0],'GHQ_0'])\n",
    "        self.prep_col_names('Qual','1',3,'2')\n",
    "        for filter_kw, prefix in [('baseline','0'),('day 10','1'),('day 30','2')]:\n",
    "            self.prep_col_names(filter_kw,prefix)\n",
    "        self.reshape_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "class Data_Explorer:\n",
    "    \"\"\"\n",
    "    Class for initial data exploration.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_df_long,group_col):\n",
    "        self.in_df_long = in_df_long\n",
    "        self.group_col = group_col\n",
    "    \n",
    "    def show_univariate_distributions(self, in_var_name, plot_type):\n",
    "        pass\n",
    "\n",
    "    def show_bivariate_distributions(self, var_names):\n",
    "        pass\n",
    "    \n",
    "    def describe_baseline(self, var_names):\n",
    "        \"\"\"\n",
    "        Describe the sample at baseline.\n",
    "        \"\"\"\n",
    "        # Group = A\n",
    "        # Group = B\n",
    "        for group_name in self.in_df_long.Group.unique():\n",
    "            describe_df = self.in_df_long.loc[(self.in_df_long.time==0) &\n",
    "                                                    (self.in_df_long.Group==group_name),\n",
    "                                                     var_names].describe()\n",
    "            print(f\"Group {group_name}: {describe_df}\")\n",
    "    \n",
    "    def sample_describe(self,var_names: list, group_by = None):\n",
    "        \"\"\"\n",
    "        describe the sample at baseline\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        var_names: list of str\n",
    "            variables to describe\n",
    "        group_by:    str\n",
    "            if describing for more than one group,\n",
    "            specify name of group col\n",
    "        \"\"\"\n",
    "        if not group_by:\n",
    "            self.describe_df = self.in_df_long.loc[self.in_df_long.time==0, var_names].describe()\n",
    "        else:\n",
    "            var_names.extend([group_by])\n",
    "            self.describe_df = self.in_df_long.loc[:,var_names].groupby(group_by).describe()\n",
    "        print(self.describe_df.T)\n",
    "    \n",
    "    def get_baseline_diffs(self, var_name):\n",
    "        \"\"\"\n",
    "        Test for baseline differences.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        var_name: str\n",
    "            name of column to perform test on\n",
    "        \n",
    "        Returns\n",
    "            statistic and p-value\n",
    "        \"\"\"\n",
    "        _, norm_pval = stats.normaltest(self.in_df_long.loc[:,var_name])\n",
    "        if norm_pval<0.05:\n",
    "            non_parametric = 1\n",
    "            print(f\"Feature{var_name} is not normally distributed.\\nUsing Mann Whitney U test.\")\n",
    "        else:\n",
    "            non_parametric = None\n",
    "\n",
    "        group_names = self.in_df_long[self.group_col].unique()\n",
    "        samp1 = self.in_df_long.loc[(self.in_df_long[self.group_col] == group_names[0])&(self.in_df_long.time == 0),var_name]\n",
    "        samp2 = self.in_df_long.loc[(self.in_df_long[self.group_col] == group_names[1])&(self.in_df_long.time == 0),var_name]\n",
    "\n",
    "        if not non_parametric:\n",
    "            stat,p_val = stats.ttest_ind(samp1, samp2, nan_policy = 'omit')\n",
    "        else:\n",
    "            stat,p_val = stats.mannwhitneyu(samp1, samp2)\n",
    "        \n",
    "        if p_val<0.05:\n",
    "            print(f\"\\nGroups differ significantly at baseline on feature {var_name} (pval: {p_val}).\")\n",
    "        else:\n",
    "            print(f\"\\nNo significant baseline differences detected on feature {var_name} (pval:{p_val}).\\n\")\n",
    "        return stat, p_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Preprocess_Dataframe(in_df)\n",
    "pp.prepare_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GHQ</th>\n",
       "      <th>SWLS</th>\n",
       "      <th>PSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.578947</td>\n",
       "      <td>24.184211</td>\n",
       "      <td>16.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.853462</td>\n",
       "      <td>5.727389</td>\n",
       "      <td>5.251024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.750000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>19.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             GHQ       SWLS        PSS\n",
       "count  38.000000  38.000000  38.000000\n",
       "mean    3.578947  24.184211  16.684211\n",
       "std     2.853462   5.727389   5.251024\n",
       "min     0.000000  10.000000   5.000000\n",
       "25%     1.000000  21.000000  14.000000\n",
       "50%     3.500000  25.000000  16.000000\n",
       "75%     5.750000  28.000000  19.750000\n",
       "max     9.000000  35.000000  28.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.in_df_long.loc[(pp.in_df_long.time==0)& (pp.in_df_long.Group=='A'),['GHQ','SWLS','PSS']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group A:              GHQ       SWLS        PSS\n",
      "count  38.000000  38.000000  38.000000\n",
      "mean    3.578947  24.184211  16.684211\n",
      "std     2.853462   5.727389   5.251024\n",
      "min     0.000000  10.000000   5.000000\n",
      "25%     1.000000  21.000000  14.000000\n",
      "50%     3.500000  25.000000  16.000000\n",
      "75%     5.750000  28.000000  19.750000\n",
      "max     9.000000  35.000000  28.000000\n",
      "Group B:              GHQ       SWLS        PSS\n",
      "count  36.000000  34.000000  34.000000\n",
      "mean    3.388889  24.617647  17.794118\n",
      "std     3.227363   5.482837   5.563841\n",
      "min     0.000000  11.000000   6.000000\n",
      "25%     0.750000  21.000000  13.000000\n",
      "50%     3.000000  27.000000  18.500000\n",
      "75%     5.000000  28.000000  21.750000\n",
      "max    10.000000  33.000000  28.000000\n"
     ]
    }
   ],
   "source": [
    "de = Data_Explorer(pp.in_df_long,'Group')\n",
    "de.describe_baseline(['GHQ','SWLS','PSS'])\n",
    "#features = de.in_df_long.loc[de.in_df_long.time == 0,:].dropna(how = 'all',axis =1).columns\n",
    "#features = [f for f in features if f not in ['Group','time','id']]\n",
    "#for feature in features:\n",
    "#    de.get_baseline_diffs(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = Data_Explorer(in_df)\n",
    "dem_describe = de.sample_describe(['Gender','Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "class Data_Analyzer:\n",
    "    def __init__(self, in_df_long,id_col):\n",
    "        self.in_df_long = in_df_long\n",
    "        self.id_col = id_col\n",
    "    \n",
    "    def scale_scores(self, col_names, scaler_type):\n",
    "        \"\"\" \n",
    "        Scale questionnaire scores.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_df:  pandas Dataframe\n",
    "            Dataframe to operate on.\n",
    "        col_names:  list\n",
    "            list of column names to operate on.\n",
    "        scaler_type:    scaler type to use\n",
    "        \"\"\"\n",
    "        scaler = scaler_type\n",
    "\n",
    "        for col in col_names:\n",
    "            self.in_df_long[col+'_scaled'] = scaler.fit_transform(self.in_df_long[col].values.reshape(-1,1))\n",
    "\n",
    "    def build_lmem(self, oc_name, predictor_names, interacts = None, r_slpe = None):\n",
    "        \"\"\"\n",
    "        Use linear mixed effects model for analysis.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        oc_name:    str\n",
    "            outcome column name\n",
    "        predictor_names:    list of str\n",
    "            list of column names to use as predictors\n",
    "        interacts:  \n",
    "            Flag to indicate whether to construct the formula\n",
    "            using interactions ( pred1*pred2) or not.\n",
    "            Any value is fine, as the code only checks whether\n",
    "            this is None or not.\n",
    "        \"\"\"\n",
    "        if not interacts:\n",
    "            rh_side = '+'.join(predictor_names)\n",
    "        else:\n",
    "            rh_side = '*'.join(predictor_names)\n",
    "        self.formula = ''.join([oc_name,'~',rh_side])\n",
    "        if not r_slpe: \n",
    "            self.model_lmem = smf.mixedlm(self.formula, self.in_df_long,\n",
    "                                        groups=self.id_col,missing = 'drop').fit()\n",
    "        else:\n",
    "            self.model_lmem = smf.mixedlm(self.formula, self.in_df_long, groups=self.id_col, \n",
    "                                    re_formula = ''.join(['~',r_slpe]),missing = 'drop').fit()\n",
    "        print(f\"\\nModel results:\\n{self.model_lmem.summary()}\")\n",
    "    \n",
    "    def build_gee(self, oc_name, predictor_names, fam, cov_type, interacts = None):\n",
    "        \"\"\"\n",
    "        Use GEE approach for analysis.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        oc_name:    str\n",
    "            outcome column name\n",
    "        predictor_names:    list of str\n",
    "            list of column names to use as predictors\n",
    "        interacts:  \n",
    "            Flag to indicate whether to construct the formula\n",
    "            using interactions ( pred1*pred2) or not.\n",
    "            Any value is fine, as the code only checks whether\n",
    "            this is None or not.\n",
    "        fam:\n",
    "            Mean response structure\n",
    "        cov_type:\n",
    "            covariance structure\n",
    "        \"\"\"\n",
    "        if not interacts:\n",
    "            rh_side = '+'.join(predictor_names)\n",
    "        else:\n",
    "            rh_side = '*'.join(predictor_names)\n",
    "        self.formula = ''.join([oc_name,'~',rh_side])\n",
    "        try:\n",
    "            self.model_gee = smf.gee(self.formula,self.id_col, self.in_df_long,\n",
    "                            cov_struct = cov_type, family = fam,\n",
    "                            missing = 'drop').fit()\n",
    "        except ValueError:\n",
    "            warnings.warn(\"Covariance structure changed to Independence.\",\n",
    "                            category = UserWarning)\n",
    "            self.model_gee = smf.gee(self.formula,self.id_col, self.in_df_long,\n",
    "                            cov_struct = sm.cov_struct.Independence(),\n",
    "                            family = fam,\n",
    "                            missing = 'drop').fit()\n",
    "        print(self.model_gee.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model results:\n",
      "                               Mixed Linear Model Regression Results\n",
      "====================================================================================================\n",
      "Model:                           MixedLM                Dependent Variable:                PSS      \n",
      "No. Observations:                198                    Method:                            REML     \n",
      "No. Groups:                      72                     Scale:                             8.3824   \n",
      "Min. group size:                 1                      Log-Likelihood:                    -566.7706\n",
      "Max. group size:                 3                      Converged:                         Yes      \n",
      "Mean group size:                 2.8                                                                \n",
      "----------------------------------------------------------------------------------------------------\n",
      "                                                         Coef.  Std.Err.   z    P>|z|  [0.025 0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Intercept                                                17.794    0.967 18.397 0.000  15.898 19.690\n",
      "C(Group, Treatment('B'))[T.A]                            -1.110    1.331 -0.834 0.404  -3.719  1.499\n",
      "C(time, Treatment(0))[T.1]                               -1.187    0.817 -1.454 0.146  -2.788  0.413\n",
      "C(time, Treatment(0))[T.2]                                2.583    1.076  2.400 0.016   0.474  4.691\n",
      "C(Group, Treatment('B'))[T.A]:C(time, Treatment(0))[T.1] -0.668    1.154 -0.579 0.563  -2.930  1.594\n",
      "C(Group, Treatment('B'))[T.A]:C(time, Treatment(0))[T.2] -7.881    1.524 -5.171 0.000 -10.868 -4.894\n",
      "id Var                                                   23.424    2.617                            \n",
      "id x time Cov                                            -8.584    1.220                            \n",
      "time Var                                                  5.510    0.861                            \n",
      "====================================================================================================\n",
      "\n",
      "                                              Results: GEE\n",
      "=========================================================================================================\n",
      "Model:                             GEE                            AIC:                          1198.9478\n",
      "Link Function:                     identity                       BIC:                          3636.7602\n",
      "Dependent Variable:                PSS                            Log-Likelihood:               -593.47  \n",
      "Date:                              2022-01-09 14:07               LL-Null:                      -622.04  \n",
      "No. Observations:                  198                            Deviance:                     4652.1   \n",
      "Df Model:                          5                              Pearson chi2:                 4.65e+03 \n",
      "Df Residuals:                      192                            Scale:                        24.230   \n",
      "Method:                            IRLS                                                                  \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                          Coef.  Std.Err.    z    P>|z|   [0.025   0.975]\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                17.7941   0.9401 18.9288 0.0000  15.9516 19.6366\n",
      "C(Group, Treatment('B'))[T.A]                            -1.1099   1.2610 -0.8802 0.3788  -3.5815  1.3617\n",
      "C(time, Treatment(0))[T.1]                               -1.1871   0.7383 -1.6079 0.1079  -2.6342  0.2600\n",
      "C(time, Treatment(0))[T.2]                                2.5841   0.9729  2.6562 0.0079   0.6773  4.4909\n",
      "C(Group, Treatment('B'))[T.A]:C(time, Treatment(0))[T.1] -0.6681   1.0005 -0.6678 0.5042  -2.6290  1.2927\n",
      "C(Group, Treatment('B'))[T.A]:C(time, Treatment(0))[T.2] -7.8861   1.5380 -5.1274 0.0000 -10.9006 -4.8716\n",
      "=========================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luzia T\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\statsmodels\\genmod\\cov_struct.py:796: FutureWarning: grid=True will become default in a future version\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "da = Data_Analyzer(pp.in_df_long,\"id\")\n",
    "da.build_lmem(\"PSS\",[\"C(Group,Treatment('B'))\", \"C(time,Treatment(0))\"],interacts = 1,r_slpe = \"time\")\n",
    "da.build_gee(\"PSS\",[\"C(Group,Treatment('B'))\", \"C(time,Treatment(0))\"],sm.families.Gaussian(), sm.cov_struct.Autoregressive(),interacts = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Data_Analyzer' object has no attribute 'model_gee'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LUZIAT~1\\AppData\\Local\\Temp/ipykernel_5184/2312147855.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_gee\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Data_Analyzer' object has no attribute 'model_gee'"
     ]
    }
   ],
   "source": [
    "da.model_gee.summary2()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48186e61764c8c514947f0ef500accf59797b98e64cdc910e21ec2975c1f1025"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
